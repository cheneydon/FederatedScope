use_gpu: True
device: 0
seed: 12345
outdir: exp/isolated/msqg/50000/
federate:
  mode: standalone
  method: local
  local_update_steps: 1
  batch_or_epoch: epoch
  total_round_num: 1
  client_num: 1
#  load_from: exp/pretrain/pfednlp/st_im_ag_sq_ne_cn/group_1/ckpt/
data:
  type: pfednlp_data
  root: /mnt/dongchenhe.dch/datasets/fednlp/
  max_seq_len:
    imdb: 128
    agnews: 128
    squad: 384
    newsqa: 384
    cnndm: 384
    msqg: 384
  max_query_len:
    squad: 128
    newsqa: 128
  trunc_stride:
    squad: 128
    newsqa: 128
  max_tgt_len:
    cnndm: 128
    msqg: 64
  all_batch_size:
    imdb: 32
    agnews: 32
    squad: 32
    newsqa: 32
    cnndm: 16
    msqg: 4 #16
  num_workers: 0
  cache_dir: cache
model:
  type: pfednlp_model
  model_type: bert-base-uncased #huawei-noah/TinyBERT_General_4L_312D
  num_dec_layers: 6 #2
  num_labels:
    imdb: 2
    agnews: 4
    squad: 2
    newsqa: 2
trainer:
  type: pfednlp_trainer
  disp_freq: 50
  val_freq: 100000000  # eval freq across batches
eval:
  split: ['test']
  report: ['raw']
  best_res_update_round_wise_key: test_loss
  freq: 100000000  # eval freq across rounds
test:
  temp_dir: temp
